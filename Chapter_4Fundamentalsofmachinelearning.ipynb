{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_4Fundamentalsofmachinelearning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOb8C6TU6FFZwQi6KYCVyqr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abernauer/Deep-Learning-with-Python/blob/master/Chapter_4Fundamentalsofmachinelearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYV88HvgOB_7",
        "colab_type": "text"
      },
      "source": [
        "* Central problem of machine learning: overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de1w20dFOegH",
        "colab_type": "text"
      },
      "source": [
        "#4.1 Four branches of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB5XyxSSPMCQ",
        "colab_type": "text"
      },
      "source": [
        "In the previous examples, we covered: binary classification, multiclass classification, and scalar regression. All three fall under *supervised learning*, where the goal is to learn the relationship between training inputs and training targets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsxUrCAuPuOk",
        "colab_type": "text"
      },
      "source": [
        "#4.1.1 Supervised learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfDKY1GXP-Y1",
        "colab_type": "text"
      },
      "source": [
        "Supervised learning consists of learning to map input data to known targets(also called *annotations*), given a set of examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuZ9nC5YQdFR",
        "colab_type": "text"
      },
      "source": [
        "Although supervised learning mostly consists of classification and regression, there are more exotic variants as well:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDg3rhKIQsFG",
        "colab_type": "text"
      },
      "source": [
        "* Sequence generation -- Given a picture, predict a caption describing it. Sequence generation can sometimes be reformulated as a series of classification (such as repeatedly predicting a word or token in a sequence).\n",
        "* *Syntax tree prediction* -- Given a sentence , predict its decomposition into a syntax tree.\n",
        "* *Object detection*--Given a picture, draw a bounding box around certain objects inside the picture. This can also be expressed as a classification problem(given many candidate bounding boxes, classify the contents of each one) or as a joint classification and regression problem, where the bounding-box coordinates are predicted via vector regression.\n",
        "* *Image segmentation*--Given a picture, draw a pixel-level mask on a specific object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttgmCeIzSyTO",
        "colab_type": "text"
      },
      "source": [
        "#4.1.2 Unsupervised learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11XkP7d_UGE5",
        "colab_type": "text"
      },
      "source": [
        "Unsupervised learning is the bread and butter of data analytics, and it's often a necessary step in better understanding a dataset before attempting to solve a supervised-learning problem. *Dimensionality reduction* and *clustering* are well-known categories of unsupervised learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiBRtMkuU6OW",
        "colab_type": "text"
      },
      "source": [
        "#4.1.3 Self-supervised learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sQcP_DNVLk3",
        "colab_type": "text"
      },
      "source": [
        "Self-supervised learning is supervised learning without human-annotated labels--you can think of it as supervised learning without any humans in the loop. Labels are still involved, but they're generated from the input data, typically using a heuristic algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KoF4LBEXc74",
        "colab_type": "text"
      },
      "source": [
        "For instance, *autoencoders* are a well-known instance of self-supervised learning, where the generated targets are the input, unmodified. In the same way, trying to predict the next frame in a video, given past frames, or the next word in a text, given previous words, are instances of self-supervised learning. Note that the distinction between supervised, self-supervised, and unsupervised learning can be blurry sometimes-- these categories are more of a continuum withouth solid borders. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Wf5bilYmSt",
        "colab_type": "text"
      },
      "source": [
        "#4.1.4 Reinforcement learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqf03I1PYtlz",
        "colab_type": "text"
      },
      "source": [
        "In reinforcement learning, an *agent* receives information about its environment and learns to choose actions that will maximize some reward. For instance, a neural network that \"looks\" at a video game screen and outputs game actions in order to maximize its score can be trained via reinforcement learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFAE3ZaWfTN0",
        "colab_type": "text"
      },
      "source": [
        "#Classification and regression glossary\n",
        "\n",
        "* Sample or input--One data point that goes into your model.\n",
        "* Prediction or output-- What comes out of your model.\n",
        "* Target -- The truth, What your model should ideally have predicted, according to an external source of data.\n",
        "* Prediction error or loss value-- A measure of the distance between your model's prediction and the target.\n",
        "* Classes-- A set of possible labels to choose from in a classification problem. For example, when classifying cat and dog pictures, \"dog\" and \"cat\" are the two classes.\n",
        "* Ground-truth or annotations-- All targets for a dataset, typically collected by humans.\n",
        "* Binary classification -- A classification task where each input sample should be categorized into two exclusive categories.\n",
        "* Multiclass classification-- A classification task where each input sample should be categorized into more than two categories: for instance, classifying handwritten digits.\n",
        "* Multilabel classification-- A classification task where each input sample can be assigned multiple labels. For instances, a given image may contain both a cat and a dog and should be annotated both with the \"cat\" label and the \"dog\" label. The number of labels per image is usually variable.\n",
        "* Vector regression -- A task where the target is a set of continous values: for example, a continuous vector.\n",
        "* Mini-batch or batch -- A small set of samples(typically between 8 and 128) that are processed simultaneously by the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlLMjBwwiqmt",
        "colab_type": "text"
      },
      "source": [
        "#4.2 Evaluating machine-learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS5vIsDYlMm5",
        "colab_type": "text"
      },
      "source": [
        "* First key problem in machine learning avoid *overfitting*. Or performing better on the training data and stalling on the test data after a few iterations or epochs.\n",
        "\n",
        "* Second key problem *generalize* performance on to never before seen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR_5aCjGmCAM",
        "colab_type": "text"
      },
      "source": [
        "#4.2.1 Training, validation, and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzGf3y7hmLK5",
        "colab_type": "text"
      },
      "source": [
        "1. Split the data into three sets: training, validation, and test.\n",
        "2. Train on your training data and evaluate you model on the validation data.\n",
        "3. Test the model on the test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL8__xbVoncW",
        "colab_type": "text"
      },
      "source": [
        "The validation set allows us to tune the configuration of our model: choosing the number of layers or size of the layers( *hyperparameters*). Tuning the hyperparameters is a form of *learning*: a search problem for a good configuration in some parameter space. This can result in *overfitting on the validation set*.\n",
        "\n",
        "*Information leaks* may take place if you optimize your hyperparameters too much on the validation set as you will expose information to the model that will tune it specifically for performance on the validation set. Not for the test set which we would like to perform well on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17KgonHir5i0",
        "colab_type": "text"
      },
      "source": [
        "# Simple Hold-out validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg23zRJasD--",
        "colab_type": "text"
      },
      "source": [
        "Set apart some fraction of your data as your test set. Train on the remaining data, and evauate on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bib7w7luvgYU",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        " import numpy as np\n",
        " from keras import models\n",
        "\n",
        " num_validation_samples = 10000\n",
        "\n",
        " np.random.shuffle(data)\n",
        "\n",
        " validation_data = data[:num_validation_samples]\n",
        " data = data[num_validation_samples:]\n",
        "\n",
        " training_data = data[:]\n",
        "\n",
        " model = get_model()\n",
        " model.train(training_data)\n",
        " validation_score = model.evaluate(validation_data)\n",
        "\n",
        " # At this point you can tune your model.\n",
        " # retrain it, evaluate it, tune it again.\n",
        "\n",
        " model = get_model()\n",
        " model.train(np.concatenate([training_data,\n",
        "                             validation_data]))\n",
        " test_score = model.evaluate(test_data)\n",
        "\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2A_XnnkBVrd",
        "colab_type": "text"
      },
      "source": [
        "This is the simplest evaluation protocol, and it suffers from one flaw: if little data is available, then your validattion and test sets may contain too few samples to be statistically representative of the data at hand. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2NhVNpJChyK",
        "colab_type": "text"
      },
      "source": [
        "# K-FOLD Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpZpT-mRCsCe",
        "colab_type": "text"
      },
      "source": [
        "With this approach, you split your data into K partitions of equal size. For each partition i, train a model on the remaining K-1 partitions, and evaluate it on partition i. Your final score is then the averages of the K scores obtained. This method is helpful when the performance of your model shows significant variance based on your training test split. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSM4cTIDCrHd",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "k = 4\n",
        "num_validation_samples = len(data) // k\n",
        "\n",
        "np.random.shuffle(data)\n",
        "\n",
        "validation_scores = []\n",
        "for fold in range(k):\n",
        "    validation_data = data[num_validation_samples * fold:\n",
        "    num_validation_samples * (fold + 1)]\n",
        "    training_data = data[:num_validation_samples * fold] + \n",
        "    data[num_validation_samples * (fold + 1):]\n",
        "    model = get_model()\n",
        "    model.train(training_data)\n",
        "    validation_score = model.evaluate(validation_data)\n",
        "    validation_scores.append(validation_score)\n",
        "validation_score = np.average(validation_scores)\n",
        "\n",
        "model = get_model()\n",
        "model.train(data)\n",
        "test_score = model.evaluate(test_data)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEsNhRz-F7Nl",
        "colab_type": "text"
      },
      "source": [
        "#Iterated K-FOLD VALIDATION WITH SHUFFLING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeNBPyJtGDUZ",
        "colab_type": "text"
      },
      "source": [
        "It consists of applying K-fold validation multiple times, shuffing the data every time before splitting it K ways. The final score is the average of the scores obtained at each run of K-fold validation. Note that you end up training and evaluating P X K models(where P is the number of iterations you use), which can be very expensive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueJnhVVkG0zn",
        "colab_type": "text"
      },
      "source": [
        "#4.2.2 Things to keep in mind"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GN4q3jxHF2l",
        "colab_type": "text"
      },
      "source": [
        "* *Data representiveness*-- You want both your taining set and test set to be representative of the data at hand. For instance, if you're trying to classify images of digits, and you're starting from an array of samples where the samples are ordered by their class, takinge the first 80% of the array as your training set and the remaining 20% as your test set will result in your training set containing only classes 0-7, whereas your test set contatins only classes 8-9. This seems like a ridiculous mistake, but it's surprisingly common. For this reason, you usually should *randomly shuffle* your data before splitting it into training and test sets.\n",
        "\n",
        "* *The arrow of time*-- If you're trying to predict the future given the past, you should not randomly shuffle your data before splitting it, because doing so will create a *temporal leak*: your model will effectively be trained on data from the future. In such situations you should always make sure all data in your test set *posterior* to the data in the training set.\n",
        "\n",
        "* *Redundancy in your data*-- If some data points in your data appear twice, then shuffling the data and splitting it into a training set and validation set will result in redundacy between the training and validation sets. In effect, you'll be testing on part of your training data, which is the worst thing you can do! Make sure your training set and validation set are disjoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryMAEGudJ8nC",
        "colab_type": "text"
      },
      "source": [
        "#4.3 Data preprocessing, feature engineering, and feature learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZwEZz_waz0L",
        "colab_type": "text"
      },
      "source": [
        "In addition to model evaluation, an important question we must must tackle before we dive deeper into model development is the following: how do you prepare the input data and targets before feeding them into a neural network?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKeIjrP8jAZ3",
        "colab_type": "text"
      },
      "source": [
        "#4.3.1 Data preprocessing for neural networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QuVgTNnjTCe",
        "colab_type": "text"
      },
      "source": [
        "#Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn2j_MSSjXQH",
        "colab_type": "text"
      },
      "source": [
        "All inputs and targets in a neural network must be tensors of floating-point "
      ]
    }
  ]
}