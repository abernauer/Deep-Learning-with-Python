{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter3_Getting_started_with_neural_networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPBdMSrXX+bjQy2LiW2wnYx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abernauer/Deep-Learning-with-Python/blob/master/Chapter3_Getting_started_with_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfx-vE8r0zt2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Chapter 3 Getting started with neural networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hQXwxmv1ZYQ",
        "colab_type": "text"
      },
      "source": [
        "#3.1 Anatomy of a neural networks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EWOy38I1jnc",
        "colab_type": "text"
      },
      "source": [
        "Training a neural network revolves around the following objects:\n",
        "\n",
        "* Layers which are combined into a network (or model)\n",
        "* The input data and corresponding targets\n",
        "* The loss function, which defines the feedback signal used for learning.\n",
        "* The optimizer, which determines how learning proceeds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5LwzShc2U69",
        "colab_type": "text"
      },
      "source": [
        "Add diagram of the components and how they interact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWlHQitz2fyY",
        "colab_type": "text"
      },
      "source": [
        "#3.1.1 Layers the building blocks of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDpqPFk62mhe",
        "colab_type": "text"
      },
      "source": [
        "The fundamental data structure in neural networks is the *layer*, to which you were introduced in chapter 2. A layer is a data-processing module that takes as input one or more tensors and that outputs one or more tensors. Some layers are stateless but more frequently layers have a state: the layer's *weights*, one or several tensors learned with stochastic gradient descent, which together contain the network's *knowledge*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytLYJo0ytNiW",
        "colab_type": "text"
      },
      "source": [
        "Different layers are appropriate for different tensor formats and different types of data processing. For instance, simple vector data, stored in 2D tensors of shape (samples, features), is often processed by *densely connected* layers, also called *fully connected* or *dense* layers. Sequence data, stored in 3D tensors of shape (samples, timesteps, features), is typically processed by *recurrent* layers such as an *LSTM* layer.\n",
        "Image data, stored in 4D tensor, is usually processed by 2D convolution layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAC1oivFu2Ia",
        "colab_type": "text"
      },
      "source": [
        "A metaphor for layers is thinking of them as LEGO bricks for deep learning. Building deep-learning models in Keras is done by clipping together compatible layers to form useful data-transformation pipelines. The notion of layer *compatibility* here refers specifically to the fact that every layer will only accept input tensor of a certain shape and will return output tensors of a certain shape. Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nmdRQQAwA-b",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from keras import layers\n",
        "\n",
        "layer = layers.Dense(32, input_shape=(784,))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4CmDBXfwWyD",
        "colab_type": "text"
      },
      "source": [
        "We're creating a layer that will only accept as input 2D tensors where the first dimension is 784(axis 0, the batch dimension, is unspecified, and thus any value would be accepted.) This layer will return a tensor where the first dimension has been transformed to be 32."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5jLWc8Dw5vI",
        "colab_type": "text"
      },
      "source": [
        "Thus this layer can only be connected to a downstream layer that expects 32-dimensional vectors as its input. When using Keras, you don't have to worry about compatibility, because the layers you add to your models are dynamically built to match the shape of the incoming layer. For instance, suppose you write the following: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYwyIxulyVha",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, input_shape=(784,)))\n",
        "model.add(layers.Dense(32))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHYc_iOUy-7y",
        "colab_type": "text"
      },
      "source": [
        "The second layer will automatically infer its input shape as being the the output shape of the layer that came before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOTWzMAuzTcJ",
        "colab_type": "text"
      },
      "source": [
        "#3.1.2 Models: networks of layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zceheV1d0Dq2",
        "colab_type": "text"
      },
      "source": [
        "A deep-learning model is a directed, acyclic graph of layers. The most common instance is a linear stack of layers, mapping a single input to a single output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek8rClDZ0c2b",
        "colab_type": "text"
      },
      "source": [
        "Some broader networks include:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJGWYNEX0nc9",
        "colab_type": "text"
      },
      "source": [
        "* Two-branch networks\n",
        "* Multihead networks\n",
        "* Inception blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA5nhR9A0y_Y",
        "colab_type": "text"
      },
      "source": [
        "The topology of a network defines a *hypothesis space*. You may remember that in chapter 1, we defined machine learning as \"searching for useful representations of some input data, within a predefined space of possibilities, using guidance from a feedback signal\". By choosing a network topology, you constrain your *space of possibilities* (hypothesis space) to a specific series of tensor operations, mapping input data to output data. What you'll then be searching for is a good set of values for the weight tensors involved in these tensor operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-u7zffa28Pb",
        "colab_type": "text"
      },
      "source": [
        "#3.1.3 Loss functions and optimizers: keys to configuring the learning process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIH40nrY3H4J",
        "colab_type": "text"
      },
      "source": [
        "Once the network architecture is defined, you still have to choose two more things:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOWZEQ763R0L",
        "colab_type": "text"
      },
      "source": [
        "* Loss function (objective function)-- The quantity that will be minimized during training. It represents a measure of success for the task at hand.\n",
        "* Optimizer--Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent(SGD)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEW1zQ3n31ev",
        "colab_type": "text"
      },
      "source": [
        "Choosing the right objective function for the right problem is extremely important: your network will take any shortcut it can, to minimize the loss; so if the objective doesn't fully correlate with success for the task at hand your network will end up doing things you may not have wanted. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1UDh-VV5h0b",
        "colab_type": "text"
      },
      "source": [
        "Guidelines for chosing the correct loss:\n",
        "* binary crossentropy\n",
        "  - two-class classification problem\n",
        "* categorical crossentropy\n",
        "  - many-class classification problem\n",
        "* mean squared error\n",
        "  - regression problems\n",
        "* Connectionist temporal classification\n",
        "  - sequence-learning problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAmTKUn49V_5",
        "colab_type": "text"
      },
      "source": [
        "#3.2.2 Developing with Keras: a quick overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OswH9C7CAR9m",
        "colab_type": "text"
      },
      "source": [
        "The typical Keras workflow looks like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3hWIO5uAct9",
        "colab_type": "text"
      },
      "source": [
        "1. Define your training data: input tensors and target tensors.\n",
        "2. Define a network of layers (or *model*) that maps your inputs to your targets.\n",
        "3. Configure the learning process by choosing a loss function, an optimizer, and some metrics to monitor.\n",
        "4. Iterate on your training data by calling the fit() method of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HPmQvfRBF3M",
        "colab_type": "text"
      },
      "source": [
        "There are two ways to define a model: using the *Sequential* class(only for linear stacks of layers, which is the most common architecture) or the *functional* API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS5dXKiEEA4e",
        "colab_type": "text"
      },
      "source": [
        "As a refresher, here's a two-layer model defined using the *Sequential* class (note that we're passing the expected shape of the input data to the first layer):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxiMq3HUEY5X",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(784,)))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAvkUJj7E-2S",
        "colab_type": "text"
      },
      "source": [
        "And the same model using the functional API:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoOpBpnrFEVI",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "input_tensor = layers.Input(shape=(784,))\n",
        "x = layers.Dense(32, activation='relu')(input_tensor)\n",
        "\n",
        "output_tensor = layers.Dense(10, activation='softmax') (x)\n",
        "model = models.Model(inputs=input_tensor, outputs=output_tensor)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_yYOouBGr0F",
        "colab_type": "text"
      },
      "source": [
        "With the functional API, you're maniplating the data tensors that the model proccesses and applying layers to this tensor as if they were functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKGXgbs2HHcs",
        "colab_type": "text"
      },
      "source": [
        "Once your model architectre is defined, it doesn't matter whether you used a *Sequential* model or the functional API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKSsV5S3HV-f",
        "colab_type": "text"
      },
      "source": [
        "The learning process is configured in the compilation step, where you specify the optimizer and loss function(s) that the model should use, as well as the metrics to monitor during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTSF3nTgHtnX",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "loss='mse',\n",
        "metrics=['accuracy'])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eF_CTn_ISX8",
        "colab_type": "text"
      },
      "source": [
        "Finally, the learning process consists of passing Numpy arrays of input data ( and the corresponding target data) to the model via the fit() method, similar to what you would do in SciKit-Learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP5qEdG4IupH",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "model.fit(input_tensor, target_tensor, batch_size=128, epochs=10)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1rb1cc7MsTJ",
        "colab_type": "text"
      },
      "source": [
        "#3.4 Classifying movie reviews: a binary classification example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32MgITYLNB1L",
        "colab_type": "text"
      },
      "source": [
        "Two-class classification, or binary classifictaion, may be the most widely applied kind of machine-learning problem. In this example, you'll learn to classify movie reviews as positive or negative, based on the text contents of the reviews.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2bTt0znRZx5",
        "colab_type": "text"
      },
      "source": [
        "#3.4.1 The IMDB dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pny_vNOFRfKu",
        "colab_type": "text"
      },
      "source": [
        "You'll work with th IMDB dataset: as set of 50,000 highly polarized reviews from the Internet Movie Database. They're split into 25,000 reviews for training and 25,000 reviews for testing, each set consisting of 50% negative and 50% positive reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPlfB_6wUHWN",
        "colab_type": "text"
      },
      "source": [
        "Why use separate training and test sets? Because you should never test a machine learning model on the same data you used to train it! Just because a model performs well on its training data doesn't mean it will perform well on data it has never seen; and what you care about is your model's performance on new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98-T_OwtVD2V",
        "colab_type": "text"
      },
      "source": [
        "The following code will load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33ngwhDoNF4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "(train_data, train_labels),  (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mt8LIwAWF4f",
        "colab_type": "text"
      },
      "source": [
        "The argument num_words=10000 means you'll only keep the top 10,000 most frequently occurring words in the training data. Rare words will be discarded. This allows you to work with vector data of manageable size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6VJ4Fq8XNwT",
        "colab_type": "text"
      },
      "source": [
        "The variables train_data and test_data are lists of reviews; each review is a list of word indices(encoding a sequence of words). train_labels and test_labels are lists of 0s and 1s, where 0 stands for *negative* and 1 stands for *positive*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7buJtq6Nmf9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2466fd96-0a73-462c-c605-092f1e6c7c93"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULKLwbx1Nw18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "269c2c0c-e449-4899-ef1b-277ef3fbcb86"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T48W4vZkN1v7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d373279f-1dab-4522-82b2-aedf4ac487fe"
      },
      "source": [
        "max([max(sequence) for sequence in train_data])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKiXR2NuOcxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = ' '.join(\n",
        "    [reverse_word_index.get(i - 3, '?') for i in train_data[0]]\n",
        ")"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wAv6SW0fShE",
        "colab_type": "text"
      },
      "source": [
        "#3.4.2 Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C1Ia3gofVx3",
        "colab_type": "text"
      },
      "source": [
        "You can't feed lists of integers into a neural networks. You have to turn your lists into tensors. There are two ways to do that:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8kbHXcbfiYG",
        "colab_type": "text"
      },
      "source": [
        "* Pad your lists so that they all have the same length, turn them into an integer tensor of shape (samples, word_indices), and then use as the first layer in your network a layer capable of handling such integer tensors ( the Embedding layer, which we'll cover in detail later in the book).\n",
        "\n",
        "* One-hot encode your lists to turn them into vectors of 0s and 1s. This would mean, for instance, turning the sequence [3, 5] into a 10,000-dimensional vector that would be all 0s except for indices 3 and 5, which would be 1s. Then you could use as the first layer in your network a *Dense* layer, capable of handling floating-point vector data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rvsM0jYhqVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lfybgc35jJSu",
        "colab_type": "text"
      },
      "source": [
        "What the samples look like now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fhTr1WzjNWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a08ea904-222e-4bf7-ae01-dc6829687c67"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a3eflPkjSx5",
        "colab_type": "text"
      },
      "source": [
        "We should also vectorize the lables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORTgIZiQjZjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.array(train_labels).astype('float32')\n",
        "y_test = np.array(test_labels).astype('float32')"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVSYy74hjtRh",
        "colab_type": "text"
      },
      "source": [
        "No we can build our network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q32mNdGDjxyA",
        "colab_type": "text"
      },
      "source": [
        "#3.4.3 Building your network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8tw4lm8l6Kw",
        "colab_type": "text"
      },
      "source": [
        "The input data is vectors, and the labels are scalars(1s and 0s): this is the easiest setup you'll ever encounter. A type of network that performs well on such a problem is a simple stack of fully connected (Dense) layers with *relu* activations: Dense(16,activation='relu').\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oigAEFNimek8",
        "colab_type": "text"
      },
      "source": [
        "The argument being passed to each Dense layer (16) is the number of hidden units of the layer. A *hidden unit* is a dimension in the representation space of the layer. You may remember from chapter 2 that each *Dense* layer with a relu activation implements the following chain of tensor operations:\n",
        "```\n",
        "output = relu(dot(W, input) + b)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0MZxHIonRSI",
        "colab_type": "text"
      },
      "source": [
        "Having 16 hidden units means the weight matrix *W* will have shape(input_dimension, 16): the dot product with *W* will project the input data onto a 16-dimensional representation space. You can intuitively understand the dimensionality of your representation space as \"how much freedom you're allowing the network to have when learning the internal representations.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "282Wy18toNp6",
        "colab_type": "text"
      },
      "source": [
        "There are two key architecture decisions to be made about such a stack of *Dense* layers:\n",
        "\n",
        "* How many layers to use\n",
        "* How many hidden units to choose for each layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgQ8IL9VolSp",
        "colab_type": "text"
      },
      "source": [
        "More on this in chapter 4 we will us the following architecture:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIDYowA1otfg",
        "colab_type": "text"
      },
      "source": [
        "* Two intermediate layers with 16 hidden units each\n",
        "* A third layer that will output the scalar prediction regarding the sentiment of the current review."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHmu1WToqwiu",
        "colab_type": "text"
      },
      "source": [
        "The intermediate layers will use *relu* as their activation function, and the final layer will use a sigmoid activation so as to output a probability (a score between 0 and 1, indicating how likely the sample is to have the target \"1\": how likely the review is to be positive). A *relu* (rectified linear unit) is a function meant ot zero out negative values whereas a sigmoid \"squashes\" arbitrary values into the [0, 1] interval, outputting something that can be interpreted as a probability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El2_IwpPr0-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74k3nlv2stwa",
        "colab_type": "text"
      },
      "source": [
        "It is key to you use an activation function as it allows for non-linear transformations of the hypothesis space. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gh3BvGNs8bU",
        "colab_type": "text"
      },
      "source": [
        "Finally, we choose a loss function and an optimizer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAAr7iLntIts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80B8uQQzvRlb",
        "colab_type": "text"
      },
      "source": [
        "#3.4.4 Validating your approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP0Z1g4DvrYr",
        "colab_type": "text"
      },
      "source": [
        "In order to monitor during training the accuracy of the model on data it has never seen before, you'll create a validation set by setting apart 10,000 samples from the orginal training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl2mZLGKwBBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgtY6x91wj9o",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHMJtmMDwlxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5b7b8ee9-f755-4e9e-ca41-12b6c8756ba9"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 2s 115us/step - loss: 0.5347 - acc: 0.7886 - val_loss: 0.4206 - val_acc: 0.8501\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 2s 108us/step - loss: 0.3234 - acc: 0.9021 - val_loss: 0.3169 - val_acc: 0.8852\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 106us/step - loss: 0.2377 - acc: 0.9254 - val_loss: 0.2998 - val_acc: 0.8805\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 2s 106us/step - loss: 0.1902 - acc: 0.9380 - val_loss: 0.2790 - val_acc: 0.8887\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 2s 106us/step - loss: 0.1569 - acc: 0.9507 - val_loss: 0.2765 - val_acc: 0.8897\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 2s 107us/step - loss: 0.1300 - acc: 0.9601 - val_loss: 0.3111 - val_acc: 0.8796\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 2s 104us/step - loss: 0.1114 - acc: 0.9664 - val_loss: 0.2992 - val_acc: 0.8840\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 2s 105us/step - loss: 0.0915 - acc: 0.9737 - val_loss: 0.3366 - val_acc: 0.8762\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 2s 107us/step - loss: 0.0784 - acc: 0.9783 - val_loss: 0.3340 - val_acc: 0.8843\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 2s 105us/step - loss: 0.0635 - acc: 0.9837 - val_loss: 0.3650 - val_acc: 0.8763\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 2s 105us/step - loss: 0.0531 - acc: 0.9875 - val_loss: 0.3974 - val_acc: 0.8778\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 2s 105us/step - loss: 0.0444 - acc: 0.9897 - val_loss: 0.4022 - val_acc: 0.8782\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 2s 105us/step - loss: 0.0353 - acc: 0.9923 - val_loss: 0.4406 - val_acc: 0.8772\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 2s 105us/step - loss: 0.0283 - acc: 0.9949 - val_loss: 0.4691 - val_acc: 0.8753\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 2s 105us/step - loss: 0.0229 - acc: 0.9965 - val_loss: 0.4935 - val_acc: 0.8737\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 2s 107us/step - loss: 0.0161 - acc: 0.9983 - val_loss: 0.5473 - val_acc: 0.8708\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 2s 105us/step - loss: 0.0136 - acc: 0.9987 - val_loss: 0.5801 - val_acc: 0.8639\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 2s 107us/step - loss: 0.0102 - acc: 0.9994 - val_loss: 0.6116 - val_acc: 0.8650\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 2s 106us/step - loss: 0.0086 - acc: 0.9991 - val_loss: 0.6405 - val_acc: 0.8673\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 2s 106us/step - loss: 0.0077 - acc: 0.9991 - val_loss: 0.6670 - val_acc: 0.8689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EVDxQplxz41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history.history"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNjVs-Nhx-C5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "61dc8ade-5fbf-4826-cd0e-a2dc8294da8f"
      },
      "source": [
        "history_dict.keys()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_N2-ydXySOX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bfc95d67-011f-4197-a126-3561ef6f9531"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk2DTffsFgKD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a11dcb00-9abb-4a46-c910-1081869214c4"
      },
      "source": [
        "plt.clf()\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHyr91DaHEz7",
        "colab_type": "text"
      },
      "source": [
        "Training loss decreases with every epoch, and the training accuracy increases with every epoch. This is a sign of overfitting. Let's limit the network to 4 epochs and see how it performs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PENFbec5H9Mz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7230c9c4-0e05-4a66-8f4c-59738038bdc9"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "25000/25000 [==============================] - 2s 80us/step - loss: 0.4545 - accuracy: 0.8214\n",
            "Epoch 2/4\n",
            "25000/25000 [==============================] - 2s 76us/step - loss: 0.2583 - accuracy: 0.9110\n",
            "Epoch 3/4\n",
            "25000/25000 [==============================] - 2s 75us/step - loss: 0.1978 - accuracy: 0.9302\n",
            "Epoch 4/4\n",
            "25000/25000 [==============================] - 2s 76us/step - loss: 0.1672 - accuracy: 0.9405\n",
            "25000/25000 [==============================] - 2s 63us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otCaBDX6JfpK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e6bc88be-6604-4f85-b160-fecfa80846e2"
      },
      "source": [
        "results"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2977292294692993, 0.8833600282669067]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSmb6hbXJl-h",
        "colab_type": "text"
      },
      "source": [
        "The final results acheive an accuracy of 86%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbUpgvrvT2Sk",
        "colab_type": "text"
      },
      "source": [
        "#3.4.5 Using a trained network to generate predictions on new data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1D-hqCOUKm7",
        "colab_type": "text"
      },
      "source": [
        "You can generate the likelihood of reviews being positive by using the *predict* method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6u3rLulUYpo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "afa3734d-844d-45c8-e1a0-eadf18ddf027"
      },
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.21914852],\n",
              "       [0.9999547 ],\n",
              "       [0.9191835 ],\n",
              "       ...,\n",
              "       [0.13547519],\n",
              "       [0.06800082],\n",
              "       [0.63251185]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02RLfystYGBc",
        "colab_type": "text"
      },
      "source": [
        "#3.4.6 Further experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTHppvxZYuVG",
        "colab_type": "text"
      },
      "source": [
        "fill in later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vngs0bHYwbC",
        "colab_type": "text"
      },
      "source": [
        "#3.4.7 Wrapping up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m9BB_l9Y1Zq",
        "colab_type": "text"
      },
      "source": [
        "Fill in later"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oTCDDQlY5cf",
        "colab_type": "text"
      },
      "source": [
        "#3.5 Classifying newswires: a multiclass classification example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDhC9dxxZhco",
        "colab_type": "text"
      },
      "source": [
        "In the previous section, you saw how to classify vector inputs into two mutually exclusive classes using a densely connected neural network. But what happens when you have more than two classes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTKPYb0SZ66h",
        "colab_type": "text"
      },
      "source": [
        "In this section, you'll build a network to classify Reuters newswires into 46 mutually exclusive topics. Because you have many classes, this problem is an instance of *multiclass classification*; and because each data point should be classified into only one category, the problem is more specifically an instance of *single-label, multiclass classification*. If each data point could belong to multiple categories, you'd be facing a *multilabel, multiclass classification* problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksrorcK8bZDg",
        "colab_type": "text"
      },
      "source": [
        "#3.5.1 The Reuters dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsWpGTi0dLoi",
        "colab_type": "text"
      },
      "source": [
        "You'll work with the *Reuters* dataset, a set of short newswires and their topics, published by Reuters in 1986. It's a simple, widely used toy dataset for text classification. There are 46 different topics; some topics are more represented than others, but each topic has at least 10 examples in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkKALCDvxQc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd5oVruvxwLv",
        "colab_type": "text"
      },
      "source": [
        "I am restricting the the data to the 10,000 most frequently occurring words found in the data with the argument num_words=10000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXYgx7fiyYTo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "009b923b-ac13-4b2b-909e-dcc6b3f4f22b"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8982"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtozn2-EycsB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4f41b62c-6e5b-484d-f804-463887d4fbca"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng0nOplZyhSs",
        "colab_type": "text"
      },
      "source": [
        "Each example is a list of integers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUTFyQYMynuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "660f7d4b-e162-4fb9-f823-b3d95ae43d74"
      },
      "source": [
        "train_data[10]"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 245,\n",
              " 273,\n",
              " 207,\n",
              " 156,\n",
              " 53,\n",
              " 74,\n",
              " 160,\n",
              " 26,\n",
              " 14,\n",
              " 46,\n",
              " 296,\n",
              " 26,\n",
              " 39,\n",
              " 74,\n",
              " 2979,\n",
              " 3554,\n",
              " 14,\n",
              " 46,\n",
              " 4689,\n",
              " 4329,\n",
              " 86,\n",
              " 61,\n",
              " 3499,\n",
              " 4795,\n",
              " 14,\n",
              " 61,\n",
              " 451,\n",
              " 4329,\n",
              " 17,\n",
              " 12]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxbeKMFXy8nU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = dict([value, key ] for (key, value) in word_index.items())\n",
        "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5kqBvLrzvjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f705e269-666e-4bf5-9083-8f6cabbb4a02"
      },
      "source": [
        "train_labels[10]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33K0T5CV0GtM",
        "colab_type": "text"
      },
      "source": [
        "#3.5.2 Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhQdKQ8S2Uyl",
        "colab_type": "text"
      },
      "source": [
        "We can use the same code snippet to vectorize the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdWxiivI0Fe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLjvxApk3gcV",
        "colab_type": "text"
      },
      "source": [
        "In terms of vectorizing the labels we will use one-hot encoding. One-hot encoding is a widely used for categorical data, also called *categorical encoding*. Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnhgvbTCCLc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1\n",
        "    return results\n",
        "\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "one_hot_test_labels = to_one_hot(train_labels)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ7MMuGSDdsD",
        "colab_type": "text"
      },
      "source": [
        "Keras has this functionality built in:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_0vzonGDlRN",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH_Ho3BBEBIE",
        "colab_type": "text"
      },
      "source": [
        "#3.5.3 Building your network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPKK8oJiF4YZ",
        "colab_type": "text"
      },
      "source": [
        "This topic-classification problem is similar to our previous classification problem. The new constraint here: the number of output classes has gone from 2 to 46. The dimensionality of the output space is much larger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "877R3Da_GdjQ",
        "colab_type": "text"
      },
      "source": [
        "As we have a larger number of output classes we need to up the dimensionality of our Dense layers so we don't lose relevant information between layers. We will go with 64 units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXcBCpSVG36V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAYmV6cKHnEo",
        "colab_type": "text"
      },
      "source": [
        "* The last layer of the network has a size of 46. For each input sample, the network will output a 46-dimensional vector. Each entry will encode a different output class.\n",
        "* The softmax activation will output a *probability distribution* over the 46 different output classes-for every input sample. The 46 scores will sum to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIKE30DrIuK6",
        "colab_type": "text"
      },
      "source": [
        "The best loss function to use in this case is *categorical_crossentropy* It measures the distance between two probability distributions: here, between the probability distribution output by the network and the true distribution of the labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtnTjzqpJgYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OAC4b4VKBm9",
        "colab_type": "text"
      },
      "source": [
        "#3.5.4 Validating your approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smorjHbGML-g",
        "colab_type": "text"
      },
      "source": [
        "We set apart 1,000 sample in the training data as a validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obPvYvxJMXrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM6KD32SNCJ4",
        "colab_type": "text"
      },
      "source": [
        "Now, train the network for 20 iterations or epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K1jhfJzNJcR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "6c41e868-610b-4196-d7c2-5ffe23822c9b"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "7982/7982 [==============================] - 1s 145us/step - loss: 2.6141 - accuracy: 0.5273 - val_loss: 1.6982 - val_accuracy: 0.6610\n",
            "Epoch 2/20\n",
            "7982/7982 [==============================] - 1s 138us/step - loss: 1.3661 - accuracy: 0.7141 - val_loss: 1.2716 - val_accuracy: 0.7240\n",
            "Epoch 3/20\n",
            "7982/7982 [==============================] - 1s 140us/step - loss: 1.0137 - accuracy: 0.7759 - val_loss: 1.1235 - val_accuracy: 0.7480\n",
            "Epoch 4/20\n",
            "7982/7982 [==============================] - 1s 141us/step - loss: 0.8018 - accuracy: 0.8230 - val_loss: 1.0353 - val_accuracy: 0.7790\n",
            "Epoch 5/20\n",
            "7982/7982 [==============================] - 1s 139us/step - loss: 0.6373 - accuracy: 0.8646 - val_loss: 0.9653 - val_accuracy: 0.7940\n",
            "Epoch 6/20\n",
            "7982/7982 [==============================] - 1s 138us/step - loss: 0.5123 - accuracy: 0.8915 - val_loss: 0.9383 - val_accuracy: 0.8080\n",
            "Epoch 7/20\n",
            "7982/7982 [==============================] - 1s 138us/step - loss: 0.4103 - accuracy: 0.9134 - val_loss: 0.9147 - val_accuracy: 0.8180\n",
            "Epoch 8/20\n",
            "7982/7982 [==============================] - 1s 139us/step - loss: 0.3330 - accuracy: 0.9272 - val_loss: 0.9316 - val_accuracy: 0.8070\n",
            "Epoch 9/20\n",
            "7982/7982 [==============================] - 1s 138us/step - loss: 0.2807 - accuracy: 0.9387 - val_loss: 0.9048 - val_accuracy: 0.8170\n",
            "Epoch 10/20\n",
            "7982/7982 [==============================] - 1s 140us/step - loss: 0.2362 - accuracy: 0.9459 - val_loss: 0.9087 - val_accuracy: 0.8170\n",
            "Epoch 11/20\n",
            "7982/7982 [==============================] - 1s 139us/step - loss: 0.2038 - accuracy: 0.9501 - val_loss: 0.9247 - val_accuracy: 0.8170\n",
            "Epoch 12/20\n",
            "7982/7982 [==============================] - 1s 138us/step - loss: 0.1832 - accuracy: 0.9513 - val_loss: 0.9547 - val_accuracy: 0.8160\n",
            "Epoch 13/20\n",
            "7982/7982 [==============================] - 1s 142us/step - loss: 0.1617 - accuracy: 0.9536 - val_loss: 0.9565 - val_accuracy: 0.8170\n",
            "Epoch 14/20\n",
            "7982/7982 [==============================] - 1s 141us/step - loss: 0.1451 - accuracy: 0.9540 - val_loss: 0.9836 - val_accuracy: 0.8170\n",
            "Epoch 15/20\n",
            "7982/7982 [==============================] - 1s 141us/step - loss: 0.1412 - accuracy: 0.9555 - val_loss: 1.0161 - val_accuracy: 0.8110\n",
            "Epoch 16/20\n",
            "7982/7982 [==============================] - 1s 139us/step - loss: 0.1310 - accuracy: 0.9560 - val_loss: 1.0421 - val_accuracy: 0.8070\n",
            "Epoch 17/20\n",
            "7982/7982 [==============================] - 1s 138us/step - loss: 0.1276 - accuracy: 0.9555 - val_loss: 1.0243 - val_accuracy: 0.8120\n",
            "Epoch 18/20\n",
            "7982/7982 [==============================] - 1s 139us/step - loss: 0.1185 - accuracy: 0.9564 - val_loss: 1.0892 - val_accuracy: 0.8060\n",
            "Epoch 19/20\n",
            "7982/7982 [==============================] - 1s 139us/step - loss: 0.1146 - accuracy: 0.9584 - val_loss: 1.1163 - val_accuracy: 0.7980\n",
            "Epoch 20/20\n",
            "7982/7982 [==============================] - 1s 140us/step - loss: 0.1142 - accuracy: 0.9572 - val_loss: 1.0991 - val_accuracy: 0.8060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZzTAVV3N69s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c053bb4f-d7b0-47aa-ff23-e3b06210cc4c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0I3ODWrPORl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "662f7c69-f739-469b-ac0e-ca35b8508b52"
      },
      "source": [
        "plt.clf()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4b9GKY4Q5it",
        "colab_type": "text"
      },
      "source": [
        "After nine epochs our network begins to over fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbf0ZQajRDG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "163e5122-43c3-442d-ea49-fbc1cd2d486b"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "partial_y_train,\n",
        "epochs=9,\n",
        "batch_size=512,\n",
        "validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, one_hot_test_labels)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/9\n",
            "7982/7982 [==============================] - 1s 149us/step - loss: 2.6275 - accuracy: 0.5106 - val_loss: 1.7520 - val_accuracy: 0.6290\n",
            "Epoch 2/9\n",
            "7982/7982 [==============================] - 1s 139us/step - loss: 1.4391 - accuracy: 0.6969 - val_loss: 1.3239 - val_accuracy: 0.7140\n",
            "Epoch 3/9\n",
            "7982/7982 [==============================] - 1s 138us/step - loss: 1.0799 - accuracy: 0.7627 - val_loss: 1.1552 - val_accuracy: 0.7530\n",
            "Epoch 4/9\n",
            "7982/7982 [==============================] - 1s 139us/step - loss: 0.8548 - accuracy: 0.8151 - val_loss: 1.0492 - val_accuracy: 0.7900\n",
            "Epoch 5/9\n",
            "7982/7982 [==============================] - 1s 138us/step - loss: 0.6798 - accuracy: 0.8543 - val_loss: 0.9740 - val_accuracy: 0.8070\n",
            "Epoch 6/9\n",
            "7982/7982 [==============================] - 1s 140us/step - loss: 0.5465 - accuracy: 0.8846 - val_loss: 0.9388 - val_accuracy: 0.8070\n",
            "Epoch 7/9\n",
            "7982/7982 [==============================] - 1s 139us/step - loss: 0.4442 - accuracy: 0.9079 - val_loss: 0.8996 - val_accuracy: 0.8100\n",
            "Epoch 8/9\n",
            "7982/7982 [==============================] - 1s 139us/step - loss: 0.3564 - accuracy: 0.9240 - val_loss: 0.8984 - val_accuracy: 0.8100\n",
            "Epoch 9/9\n",
            "7982/7982 [==============================] - 1s 141us/step - loss: 0.2998 - accuracy: 0.9351 - val_loss: 0.8967 - val_accuracy: 0.8060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-89b74c9c47dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m validation_data=(x_val, y_val))\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_test_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1350\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m                 \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_array_length_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m                 \u001b[0;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    242\u001b[0m                          \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                          \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         raise ValueError('All sample_weight arrays should have '\n",
            "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 2246 input samples and 8982 target samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo35CXrnU2R4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cQFUJk3VATG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_test_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8o6XJToXlu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgrHimeygkwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXVDT1Bn1T6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "new_test = np.reshape(x_test, (1, len(x_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOk1sO4atAxM",
        "colab_type": "text"
      },
      "source": [
        "* to do \n",
        "* fill in remaining sections\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkC_ELa3Lf3r",
        "colab_type": "text"
      },
      "source": [
        "#3.6 Predicting house prices: a regression example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWHMovO_LuId",
        "colab_type": "text"
      },
      "source": [
        "Another common type of machine-learning problem is *regression* , which consistts of predicting a continuous value instead of a discrete label: for instance predicting the time that a software project will take to compe, given its specifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usYDgurEMUgy",
        "colab_type": "text"
      },
      "source": [
        "#3.6.1 The Boston Housing Price dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLwLzZMKMd6f",
        "colab_type": "text"
      },
      "source": [
        "In this example I will attempt to predict the median price of homes in a give Boston suburb in the mid-1970s, given data points about several variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJKgRf2VNBe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import boston_housing\n",
        "\n",
        "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPNRFbHKNecK",
        "colab_type": "text"
      },
      "source": [
        "Peak at the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtuxE2tENhy1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "757679b4-cbfb-48ab-9a97-2b5b7875d9de"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUV4ukYoNmgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ab7f6fc3-4945-427e-894f-e74c11e5d67e"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fy6AgBINtfV",
        "colab_type": "text"
      },
      "source": [
        "We have 404 training samples and 102 test samples, each with 13 numerical features, such as per capita crime rate, average number of rooms per dwelling, accessibilty to highways and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXEEzpOCOKVz",
        "colab_type": "text"
      },
      "source": [
        "The targets are median values of owner-occupied homes, thousands of dollar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MzNqUR3OYFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "3e503fc3-2ec0-458c-bd53-c5f31d3d3d11"
      },
      "source": [
        "train_targets"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
              "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
              "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
              "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
              "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
              "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
              "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
              "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
              "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
              "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
              "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
              "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
              "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
              "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
              "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
              "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
              "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
              "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
              "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
              "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
              "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
              "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
              "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
              "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
              "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
              "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
              "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
              "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
              "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
              "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
              "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
              "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
              "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
              "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
              "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
              "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
              "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okOJW7fsP4KN",
        "colab_type": "text"
      },
      "source": [
        "#3.6.2 Preparing the data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EODvTkaxaSzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "mean = train_data.mean(axis=0)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "train_data /= std\n",
        "\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioJdGvbtcb7E",
        "colab_type": "text"
      },
      "source": [
        "#3.6.3 Building your network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNSvpEfTcjEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu',\n",
        "                           input_shape=(train_data.shape[1],)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "    return model\n"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNoZZ6BrehnH",
        "colab_type": "text"
      },
      "source": [
        "#3.6.4 Validating your approach using K-fold validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRBbALPFpb43",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e918269c-4611-4aa2-e178-01e430726951"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 100\n",
        "all_scores = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    model = build_model()\n",
        "    model.fit(partial_train_data, partial_train_targets,\n",
        "              epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    all_scores.append(val_mae)\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-wrsqfPerjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc64859b-018c-40f3-e647-6e355cd8f673"
      },
      "source": [
        "all_scores\n",
        "np.mean(all_scores)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.5297461450099945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DilLc9o0sY_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "72cb560b-10f8-4435-dfb6-f1d1d06f1665"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 500\n",
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    model = build_model()\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "              epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    mae_history = history.history['mae']\n",
        "    all_mae_histories.append(mae_history)\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing fold # 0\n",
            "processing fold # 1\n",
            "processing fold # 2\n",
            "processing fold # 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPtaUgQoMw1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_mae_history = [\n",
        "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AAJeUSXtLOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(1, len(average_mae_history ) + 1), average_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qovQaQN7v3Bs",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH-T0eIfv7tD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def smooth_curve(points, factor=0.9):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "      if smoothed_points:\n",
        "        previous = smoothed_points[-1]\n",
        "        smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "    else:\n",
        "        smoothed_points.append(point)\n",
        "    return smoothed_points\n",
        "\n",
        "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
        "\n",
        "plt.plot(range(1, len(smooth_mae_history) +1), smooth_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78L1hTnR4l_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40537426-f7da-4d41-8de6-6f4213784502"
      },
      "source": [
        "model = build_model()\n",
        "model.fit(train_data, train_targets,\n",
        "          epochs=80, batch_size=16, verbose=0)\n",
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 0s 177us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igDLV3pg5Z9E",
        "colab_type": "text"
      },
      "source": [
        "Final model results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omHEvWDh5dwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "372a40b0-29a9-4ed1-9397-ba99eb1665ee"
      },
      "source": [
        "test_mae_score"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.721478223800659"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwZYhOQf5gkG",
        "colab_type": "text"
      },
      "source": [
        "I am off by $2,721."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUbTwtLX4nGA",
        "colab_type": "text"
      },
      "source": [
        "#3.6.5 Wrapping up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIq0k-Lq4re0",
        "colab_type": "text"
      },
      "source": [
        "fill in notes here and section on boston model performance"
      ]
    }
  ]
}