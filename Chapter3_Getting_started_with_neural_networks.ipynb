{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter3_Getting_started_with_neural_networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrT7p8oNimkcNGbbYA2Mv6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abernauer/Deep-Learning-with-Python/blob/master/Chapter3_Getting_started_with_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfx-vE8r0zt2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Chapter 3 Getting started with neural networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hQXwxmv1ZYQ",
        "colab_type": "text"
      },
      "source": [
        "#3.1 Anatomy of a neural networks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EWOy38I1jnc",
        "colab_type": "text"
      },
      "source": [
        "Training a neural network revolves around the following objects:\n",
        "\n",
        "* Layers which are combined into a network (or model)\n",
        "* The input data and corresponding targets\n",
        "* The loss function, which defines the feedback signal used for learning.\n",
        "* The optimizer, which determines how learning proceeds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5LwzShc2U69",
        "colab_type": "text"
      },
      "source": [
        "Add diagram of the components and how they interact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWlHQitz2fyY",
        "colab_type": "text"
      },
      "source": [
        "#3.1.1 Layers the building blocks of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDpqPFk62mhe",
        "colab_type": "text"
      },
      "source": [
        "The fundamental data structure in neural networks is the *layer*, to which you were introduced in chapter 2. A layer is a data-processing module that takes as input one or more tensors and that outputs one or more tensors. Some layers are stateless but more frequently layers have a state: the layer's *weights*, one or several tensors learned with stochastic gradient descent, which together contain the network's *knowledge*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytLYJo0ytNiW",
        "colab_type": "text"
      },
      "source": [
        "Different layers are appropriate for different tensor formats and different types of data processing. For instance, simple vector data, stored in 2D tensors of shape (samples, features), is often processed by *densely connected* layers, also called *fully connected* or *dense* layers. Sequence data, stored in 3D tensors of shape (samples, timesteps, features), is typically processed by *recurrent* layers such as an *LSTM* layer.\n",
        "Image data, stored in 4D tensor, is usually processed by 2D convolution layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAC1oivFu2Ia",
        "colab_type": "text"
      },
      "source": [
        "A metaphor for layers is thinking of them as LEGO bricks for deep learning. Building deep-learning models in Keras is done by clipping together compatible layers to form useful data-transformation pipelines. The notion of layer *compatibility* here refers specifically to the fact that every layer will only accept input tensor of a certain shape and will return output tensors of a certain shape. Example: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nmdRQQAwA-b",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from keras import layers\n",
        "\n",
        "layer = layers.Dense(32, input_shape=(784,))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4CmDBXfwWyD",
        "colab_type": "text"
      },
      "source": [
        "We're creating a layer that will only accept as input 2D tensors where the first dimension is 784(axis 0, the batch dimension, is unspecified, and thus any value would be accepted.) This layer will return a tensor where the first dimension has been transformed to be 32."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5jLWc8Dw5vI",
        "colab_type": "text"
      },
      "source": [
        "Thus this layer can only be connected to a downstream layer that expects 32-dimensional vectors as its input. When using Keras, you don't have to worry about compatibility, because the layers you add to your models are dynamically built to match the shape of the incoming layer. For instance, suppose you write the following: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYwyIxulyVha",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, input_shape=(784,)))\n",
        "model.add(layers.Dense(32))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHYc_iOUy-7y",
        "colab_type": "text"
      },
      "source": [
        "The second layer will automatically infer its input shape as being the the output shape of the layer that came before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOTWzMAuzTcJ",
        "colab_type": "text"
      },
      "source": [
        "#3.1.2 Models: networks of layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zceheV1d0Dq2",
        "colab_type": "text"
      },
      "source": [
        "A deep-learning model is a directed, acyclic graph of layers. The most common instance is a linear stack of layers, mapping a single input to a single output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek8rClDZ0c2b",
        "colab_type": "text"
      },
      "source": [
        "Some broader networks include:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJGWYNEX0nc9",
        "colab_type": "text"
      },
      "source": [
        "* Two-branch networks\n",
        "* Multihead networks\n",
        "* Inception blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA5nhR9A0y_Y",
        "colab_type": "text"
      },
      "source": [
        "The topology of a network defines a *hypothesis space*. You may remember that in chapter 1, we defined machine learning as \"searching for useful representations of some input data, within a predefined space of possibilities, using guidance from a feedback signal\". By choosing a network topology, you constrain your *space of possibilities* (hypothesis space) to a specific series of tensor operations, mapping input data to output data. What you'll then be searching for is a good set of values for the weight tensors involved in these tensor operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-u7zffa28Pb",
        "colab_type": "text"
      },
      "source": [
        "#3.1.3 Loss functions and optimizers: keys to configuring the learning process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIH40nrY3H4J",
        "colab_type": "text"
      },
      "source": [
        "Once the network architecture is defined, you still have to choose two more things:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOWZEQ763R0L",
        "colab_type": "text"
      },
      "source": [
        "* Loss function (objective function)-- The quantity that will be minimized during training. It represents a measure of success for the task at hand.\n",
        "* Optimizer--Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent(SGD)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEW1zQ3n31ev",
        "colab_type": "text"
      },
      "source": [
        "Choosing the right objective function for the right problem is extremely important: your network will take any shortcut it can, to minimize the loss; so if the objective doesn't fully correlate with success for the task at hand your network will end up doing things you may not have wanted. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1UDh-VV5h0b",
        "colab_type": "text"
      },
      "source": [
        "Guidelines for chosing the correct loss:\n",
        "* binary crossentropy\n",
        "  - two-class classification problem\n",
        "* categorical crossentropy\n",
        "  - many-class classification problem\n",
        "* mean squared error\n",
        "  - regression problems\n",
        "* Connectionist temporal classification\n",
        "  - sequence-learning problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAmTKUn49V_5",
        "colab_type": "text"
      },
      "source": [
        "#3.2.2 Developing with Keras: a quick overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OswH9C7CAR9m",
        "colab_type": "text"
      },
      "source": [
        "The typical Keras workflow looks like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3hWIO5uAct9",
        "colab_type": "text"
      },
      "source": [
        "1. Define your training data: input tensors and target tensors.\n",
        "2. Define a network of layers (or *model*) that maps your inputs to your targets.\n",
        "3. Configure the learning process by choosing a loss function, an optimizer, and some metrics to monitor.\n",
        "4. Iterate on your training data by calling the fit() method of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HPmQvfRBF3M",
        "colab_type": "text"
      },
      "source": [
        "There are two ways to define a model: using the *Sequential* class(only for linear stacks of layers, which is the most common architecture) or the *functional* API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS5dXKiEEA4e",
        "colab_type": "text"
      },
      "source": [
        "As a refresher, here's a two-layer model defined using the *Sequential* class (note that we're passing the expected shape of the input data to the first layer):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxiMq3HUEY5X",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(784,)))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAvkUJj7E-2S",
        "colab_type": "text"
      },
      "source": [
        "And the same model using the functional API:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoOpBpnrFEVI",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "input_tensor = layers.Input(shape=(784,))\n",
        "x = layers.Dense(32, activation='relu')(input_tensor)\n",
        "\n",
        "output_tensor = layers.Dense(10, activation='softmax') (x)\n",
        "model = models.Model(inputs=input_tensor, outputs=output_tensor)\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_yYOouBGr0F",
        "colab_type": "text"
      },
      "source": [
        "With the functional API, you're maniplating the data tensors that the model proccesses and applying layers to this tensor as if they were functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKGXgbs2HHcs",
        "colab_type": "text"
      },
      "source": [
        "Once your model architectre is defined, it doesn't matter whether you used a *Sequential* model or the functional API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKSsV5S3HV-f",
        "colab_type": "text"
      },
      "source": [
        "The learning process is configured in the compilation step, where you specify the optimizer and loss function(s) that the model should use, as well as the metrics to monitor during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTSF3nTgHtnX",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "loss='mse',\n",
        "metrics=['accuracy'])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eF_CTn_ISX8",
        "colab_type": "text"
      },
      "source": [
        "Finally, the learning process consists of passing Numpy arrays of input data ( and the corresponding target data) to the model via the fit() method, similar to what you would do in SciKit-Learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP5qEdG4IupH",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "model.fit(input_tensor, target_tensor, batch_size=128, epochs=10)\n",
        "```"
      ]
    }
  ]
}